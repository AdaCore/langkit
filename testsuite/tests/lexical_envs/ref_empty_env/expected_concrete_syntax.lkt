lexer foo_lexer {

    @trivia() Whitespace <- p"[ \n\r\t]+"
    Def <- "def"
    Ref <- "ref"
    Open <- "open"
    LeftCurlyBracket <- "{"
    RightCurlyBracket <- "}"
    @symbol() Identifier <- p"[a-zA-Z_][a-zA-Z0-9_]*"
}
@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- list*(block)
    id <- Identifier(@Identifier)
    block <- Block(id "{" list*(item) "}")
    item <- or(
        | Decl("def" id)
        | Open("open" id)
        | Ref("ref" id)
    )
}

@abstract
class FooNode implements Node[FooNode] {
}

class Block: FooNode {
    @parse_field name: Identifier
    @parse_field items: ASTList[Item]

    env_spec {
        add_to_env_kv(node.name.symbol, node)
        add_env(names=[node.name.symbol])
    }
}

class Identifier: FooNode implements TokenNode {
    fun resolve(): Entity[FooNode] = node.children_env.get(node.symbol)?[0]
}

@abstract
class Item: FooNode {
}

class Decl: Item {
    @parse_field name: Identifier

    env_spec {
        add_to_env_kv(node.name.symbol, node)
    }
}

class Open: Item {
    @parse_field name: Identifier

    fun resolve(): LexicalEnv = {
        val n = node.name.resolve();

        n.do(
            (n) => n.children_env, default_val=null[LexicalEnv]
        )
    }

    env_spec {
        reference([node.as[FooNode]], Open.resolve)
    }
}

class Ref: Item {
    @parse_field name: Identifier

    @exported
    fun resolve(): Entity[FooNode] = node.name.resolve()
}
