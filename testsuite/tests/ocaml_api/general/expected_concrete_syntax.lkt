import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- Sequence+(node)
    node <- or(example | null_node | var | ident | string)
    example <- Example("example")
    null_node <- Null("null")
    var <- Var("var" "(" main_rule ")")
    ident <- Ident(@identifier)
    string <- StringLiteral(@string)
}

enum Color {
    case red, green, blue
}

@abstract @has_abstract_list class FooNode implements Node[FooNode] {
    @exported fun count(seq: Array[Entity[Example]]): Int = seq.length()

    @exported fun get_a(c: Char = 'a'): Char = c

    @exported fun get_eacute(c: Char = 'Ã©'): Char = c

    @exported fun identity(c: Char): Char = c

    @exported fun get_str(s: String): String = s

    @exported fun same_color(c: Color): Color = c

    @exported fun same_color_dflt(c: Color = Color.red): Color = c

    @exported fun int_double(c: BigInt): BigInt = c + c

    @exported fun me(b: Bool): FooNodeStruct = FooNodeStruct(
        node=if b then self else null[Entity[FooNode]]
    )

    @exported fun get_node(node_struct: FooNodeStruct): Entity[FooNode] =
    node_struct.node

    @exported fun iter_int(): Iterator[Int] = [1, 2, 3].to_iterator()

    @exported fun token(t: Token): Token = t
}

class Example: FooNode {
    @exported fun singleton(): SomeStruct = SomeStruct(examples=[self])
}

class Sequence: ASTList[FooNode, FooNode] {
    @exported fun all_items(): Array[Entity[FooNode]] = self.map((i) => i)

    @exported fun example_items(): Array[Entity[Example]] = self.filtermap(
        (i) => i.as![Example], (i) => i is Example
    )
}

class Ident: FooNode implements TokenNode {
    @exported fun sym(sym: Symbol): Symbol = sym
}

class Null: FooNode {
}

class StringLiteral: FooNode {
}

class Var: FooNode {
    @parse_field arg: Sequence
}

struct FooNodeStruct {
    node: Entity[FooNode]
}

struct SomeStruct {
    examples: Array[Entity[Example]]
}
