# Check the absence of memory leak when a PropertyError is raised in the middle
# of the lookup in a lexical env.
#
# This test has a simple strategy: build envs (using a simple scope scheme) so
# that a lexical env lookup starts collecting enough results in the
# Local_Results vector during the lookup of parent environments to trigger a
# dynamic allocation (Local_Results has a non-null small vector space), and so
# that the lookup of referenced environments raises a PropertyError. The data
# in Local_Results used to leak at that point.

import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- list+(scope)
    scope <- Scope(id "{" scope_content "}")
    scope_content <- list*(or(scope | use_clause | error_use_clause | ref))
    id <- Id(@Identifier)
    use_clause <- UseClause("+" id)
    error_use_clause <- ErrorUseClause("+" "error")
    ref <- Ref("=" id)
}

@abstract
class FooNode implements Node[FooNode] {
}

class ErrorUseClause: FooNode {
    fun resolve(): LexicalEnv =
        raise[LexicalEnv] PropertyError("unconditionally raised")

    env_spec {
        handle_children()
        reference(
            [node.as[FooNode]], ErrorUseClause.resolve
        )
    }
}

class Id: FooNode implements TokenNode {
    fun resolve(): Array[Entity[FooNode]] = node.node_env.get(node.symbol)
}

class Ref: FooNode {
    @parse_field name: Id

    @exported
    fun resolve(): Array[Entity[FooNode]] = node.name.resolve()
}

class Scope: FooNode {
    @parse_field name: Id
    @parse_field content: ASTList[FooNode]

    env_spec {
        add_to_env_kv(node.name.symbol, node)
        add_env()
    }
}

class UseClause: FooNode {
    @parse_field name: Id

    fun resolve(): LexicalEnv =
        node.name.resolve().map((n) => n.children_env).env_group()

    env_spec {
        handle_children()
        reference([node.as[FooNode]], UseClause.resolve)
    }
}
