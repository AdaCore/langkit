from lexer_example import foo_lexer

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule stmt_rule <- list+(or(
        | pick(@Identifier("or") or_rule)
        | pick(@Identifier("or_all_fail") or_all_fail_rule)
        | pick(@Identifier("opt") opt_rule)
        | pick(@Identifier("list") list_rule)
        | pick(@Identifier("last_fail_packrat") last_fail_packrat)
    ))

    or_rule <- or(
        # When analyzing "alt b;", the "id_equal" parser will return a node
        # (i.e. succeed) and emit diagnostics (the expected "=" token is
        # missing). The absence of a "a" token after that will make the parser
        # switch to the second alternative: diagnostics emitted for the first
        # alternative used to "leak", i.e. kept even though it's the second
        # alternative that is selected.
        | pick(@Identifier("alt") id_equal @Identifier("a") ";")
        | pick(@Identifier("alt") id ";")
    )

    or_all_fail_rule <- IdEqual(/ discard(or(
        # When all alternatives fail, the "or()" parser must retain the
        # diagnostic chain that "went the farthest" in the token stream.
        | IdEqual(discard(sub1) ";")
        | IdEqual(discard(sub2) "=" @Number ";")
        | IdEqual(discard(sub3) ";")
    )))
    sub1 <- IdEqual(@Identifier("alt") / @KwA)
    sub2 <- IdEqual(@Identifier("alt") / @KwB)
    sub3 <- IdEqual(@Identifier("alt") / @KwC)

    # Same for the "opt()" parser: diagnostics emitted when attempting to run
    # the inner parser should be discarded when aborting the "opt()".
    opt_rule <- OptNode(?(id_equal ":") id ";")

    # Same for the "list()" parser: diagnostics emitted when attempting to run
    # the inner parser should be discarded when aborting that inner parser
    # (considering that there is no item left for the list).
    list_rule <- ListNode(
        list*(pick(@Identifier("item") id_equal ";"))
        @Identifier("item")
        @Identifier("end")
    )

    # We used not to keep track of failure info in packrat tables. As a result,
    # error recovery mechanism could rely on wrong token indexes, i.e. resume
    # parsing at the wrong token index. With the following input::
    #
    #    def var ;
    #
    # The parsing rule below used to trigger an infinite loop because of this:
    #
    # * First iteration (starting at token "def"):
    #   * or() alternative #1 fails on ";", so the failure is
    #     memorized in the packrat table for the "id" rule for token ";".
    #   * Alternative #2 reaches the cut parser, then fails on the "id" parser
    #     (because of the "var" token). This returns the first list item and
    #     sets the "last failure" parser info to refer to token "var".
    # * Second iteration (starting at token "var"):
    #   * or() alternative #1 fails on "var" ("def" expected).
    #   * Alternative #2 also fails this way.
    #   * Alternative #3 reaches the cut parser, then fails on the "id" rule
    #     for token ";" (result extracted from packrat tables). Because the
    #     "last failure" info was not kept in packrat tables, this used to
    #     leave the "last failure" info to refer to token "var". This still
    #     returns the second list item and proceed to the next iteration.
    # * Third iteration: same as second, rince and repeat, and so we have an
    #   infinite loop.
    last_fail_packrat <- list*(or(
        | IdEqual("def" "var" discard(id) ";")
        | IdEqual("def" / discard(id) ";")
        | IdEqual("var" / discard(id) "=" discard(id))
    ))

    id <- Id(@Identifier)
    id_equal <- IdEqual(@Identifier / "=")
}

@abstract class FooNode implements Node[FooNode] {
}

class Id: FooNode implements TokenNode {
}

class IdEqual: FooNode {
}

class OptNode: FooNode {
    @nullable @parse_field prefix: IdEqual
    @parse_field name: Id
}

class ListNode: FooNode {
    @parse_field items: ASTList[IdEqual]
}
