import lexer_example
@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- RootNode(list+(or(decl | subdecl | other_decl), ";"))
    decl <- Decl("def" name)
    other_decl <- OtherDecl("def" "var" name)
    subdecl <- SubDecl("var" name)
    name <- Name(@identifier)

}

@abstract class FooNode : Node {
}

@abstract class BaseDecl : FooNode {

    @export fun lookup (n : Symbol): FooNode =
    node.env_lookup(node.node_env(), n)

    fun env_lookup (env : LexicalEnv, n : Symbol): FooNode = env.get_first(n)
}

class Decl : BaseDecl {
    @parse_field name : Name
}

class SubDecl : Decl {
}

class OtherDecl : BaseDecl {
    @parse_field name : Name
}

class Name : FooNode implements TokenNode {
}

class RootNode : FooNode {
    @parse_field decls : ASTList[BaseDecl]
}
