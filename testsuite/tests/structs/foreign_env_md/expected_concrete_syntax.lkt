import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- list+(def_rule)
    def_rule <- Def(name ?pick("+" name))
    name <- Name(@Identifier)
}

@abstract
class FooNode implements Node[FooNode] {
}

class Def: FooNode {
    @parse_field name: Name
    @parse_field @nullable ref: Name

    env_spec {
        add_to_env_kv(
            node.name.sym(), node, metadata=Metadata(
                node=node.ref.do(
                    (r) => r.resolve().node, default_val=null[FooNode]
                )
            )
        )
    }
}

class Name: FooNode implements TokenNode {
    fun sym(): Symbol = node.symbol

    fun resolve(): Entity[FooNode] = node.parent.node_env.get(node.sym())?[0]
}

@metadata
struct Metadata {
    @used_in_equality node: FooNode
}
