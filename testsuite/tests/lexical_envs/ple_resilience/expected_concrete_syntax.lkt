import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- defs
    defs <- list*(def_rule)
    def_rule <- or(scope | var)
    scope <- Scope(
        HasError("error") Id(@identifier) "{" defs "}"
    )
    var <- Var(Id(@identifier) "=" name)
    name <- or(
        | Prefix(name "." Id(@identifier))
        | Id(@identifier)
    )
}

@abstract class FooNode implements Node[FooNode] {
}

@abstract class DefNode: FooNode {
}

class Scope: DefNode {
    @parse_field error: HasError
    @parse_field name: Id
    @parse_field defs: ASTList[FooNode, DefNode]
}

class Var: DefNode {
    @parse_field name: Id
    @parse_field value: Name
}

@qualifier enum class HasError: FooNode {
}

@abstract class Name: FooNode {

    @export @abstract fun resolve(): Entity[FooNode]
}

class Id: Name implements TokenNode {

    fun resolve(): Entity[FooNode] = node.node_env().get_first(node)
}

class Prefix: Name {
    @parse_field prefix: Name
    @parse_field suffix: Id

    fun resolve(): Entity[FooNode] =
    node.prefix.resolve().children_env().get_first(node.suffix.symbol)
}
