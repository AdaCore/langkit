import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    @main_rule main_rule <- list+(block)
    name <- Name(@identifier)
    block <- Block(
        name decl_list "{" using_list ref_list "}"
    )
    decl_list <- pick("(" list*(decl) ")")
    using_list <- pick("(" list*(using) ")")
    ref_list <- list*(ref)
    decl <- Decl(name)
    using <- Using(name)
    ref <- Ref(name)
}

dynvar env: LexicalEnv[FooNode]

@abstract class FooNode implements Node[FooNode] {
}

class Block: FooNode {
    @parse_field name: Name
    @parse_field decls: ASTList[FooNode, Decl]
    @parse_field usings: ASTList[FooNode, Using]
    @parse_field refs: ASTList[FooNode, Ref]

    env_spec {
        add_to_env_kv(node.name.symbol, node)
        add_env()
    }
}

class Decl: FooNode {
    @parse_field name: Name

    env_spec {
        add_to_env_kv(node.name.symbol, node)
    }
}

class Name: FooNode implements TokenNode {

    @with_dynvars(env) fun ambiant_entity(): Entity[FooNode] = env.get(node)?[0]

    fun designated_env(): LexicalEnv[FooNode] =
    node.unit().root.node_env().get(node)?[0].children_env()

    @export fun entity(): Entity[FooNode] = {
        bind env = node.node_env();

        node.ambiant_entity()
    }
}

class Ref: FooNode {
    @parse_field name: Name

    @export fun entity(): Entity[FooNode] = node.as_entity.name.entity()
}

class Using: FooNode {
    @parse_field name: Name

    env_spec {
        reference([_], Name.designated_env)
    }
}
