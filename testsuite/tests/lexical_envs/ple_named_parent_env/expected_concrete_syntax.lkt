import lexer_example

@with_lexer(foo_lexer)
grammar foo_grammar {
    defs <- list*(pick(or(scope | var) ";"))
    @main_rule scope <- list+(Scope(name "{" defs "}"))
    var <- Var(id "=" name)
    id <- Id(@Identifier)
    name <- or(Prefix(name "." id) | id)
}

@abstract class FooNode implements Node[FooNode] {
}

@abstract class Name: FooNode {
    @exported @abstract fun resolve(): Entity[FooNode]

    @exported @abstract fun suffix_symbol(): Symbol

    fun scope_fqn(): String = match node {
        case p: Prefix => p.prefix.fqn()
        case _: Id => null[String]
    }

    fun fqn(): String = match node {
        case p: Prefix => p.prefix.fqn() & "." & p.suffix.fqn()
        case i: Id => i.text()
    }
}

class Id: Name implements TokenNode {
    fun resolve(): Entity[FooNode] = node.node_env().get_first(node)

    fun suffix_symbol(): Symbol = node.symbol
}

class Prefix: Name {
    @parse_field prefix: Name
    @parse_field suffix: Id

    fun resolve(): Entity[FooNode] =
    node.prefix.resolve()?.children_env().get_first(node.suffix.symbol)

    fun suffix_symbol(): Symbol = node.suffix.symbol
}

class Scope: FooNode {
    @parse_field name: Name
    @parse_field defs: ASTList[FooNode, FooNode]

    env_spec {
        set_initial_env(
            node.name.scope_fqn().do(
                (s) => DesignatedEnv(
                    kind=DesignatedEnvKind.named_env, env_name=s.to_symbol, direct_env=null[LexicalEnv[FooNode]]
                ), default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=node.parent.children_env()
                )
            )
        )
        add_to_env_kv(node.name.suffix_symbol(), node)
        add_env(names=[node.name.fqn().to_symbol])
    }
}

class Var: FooNode {
    @parse_field name: Id
    @parse_field value: Name

    env_spec {
        add_to_env_kv(node.name.symbol, node)
    }
}
